[tool.poetry]
name = "lamaapi"
version = "0.1.0"
description = "llama-cpp-pythonベースの並列処理LLMサーバー"
authors = ["Your Name <your.email@example.com>"]
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.8"
fastapi = ">=0.110.0"
uvicorn = ">=0.27.0"
python-multipart = ">=0.0.9"
pydantic = ">=2.6.0"
asyncio = ">=3.4.3"
aiohttp = ">=3.9.0"
requests = ">=2.31.0"

[tool.poetry.group.llama-cpp-python.dependencies]
llama-cpp-python = ">=0.2.43"

[tool.poetry.group.dev.dependencies]
pytest = "^7.0.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api" 