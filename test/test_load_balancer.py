#!/usr/bin/env python3
"""
ComeAPI ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç†èƒ½åŠ›ã¨è² è·åˆ†æ•£ã®å‹•ä½œç¢ºèª
"""

import asyncio
import aiohttp
import time
import json
import sys
from typing import List, Dict, Any
import concurrent.futures

class LoadBalancerTester:
    def __init__(self, base_url: str = "http://localhost:9000"):
        self.base_url = base_url
        self.session = None
        
    async def init_session(self):
        """HTTP ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–"""
        if self.session is None:
            connector = aiohttp.TCPConnector(limit=100)
            timeout = aiohttp.ClientTimeout(total=120)
            self.session = aiohttp.ClientSession(connector=connector, timeout=timeout)
    
    async def close_session(self):
        """HTTP ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‰ã˜ã‚‹"""
        if self.session:
            await self.session.close()
            self.session = None
    
    async def test_status(self):
        """ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®çŠ¶æ…‹ç¢ºèª"""
        print("ğŸ” ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼çŠ¶æ…‹ç¢ºèª...")
        try:
            await self.init_session()
            async with self.session.get(f"{self.base_url}/status") as response:
                if response.status == 200:
                    status = await response.json()
                    print(f"âœ… ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ¥ç¶šæˆåŠŸ")
                    print(f"ğŸ“Š ç·ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ•°: {status['total_backends']}")
                    print(f"ğŸŸ¢ ç¨¼åƒä¸­: {status['healthy_backends']}")
                    return status
                else:
                    print(f"âŒ ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ¥ç¶šå¤±æ•—: {response.status}")
                    return None
        except Exception as e:
            print(f"âŒ ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def test_models(self):
        """ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“‚ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ...")
        try:
            await self.init_session()
            async with self.session.get(f"{self.base_url}/models") as response:
                if response.status == 200:
                    models = await response.json()
                    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—æˆåŠŸ: {len(models['models'])}å€‹")
                    for model in models['models']:
                        print(f"   ğŸ“„ {model['name']} ({model['size_mb']:.1f}MB)")
                    return models['models']
                else:
                    print(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—å¤±æ•—: {response.status}")
                    return []
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def single_generate_request(self, prompt: str, model_name: str, request_id: int) -> Dict[str, Any]:
        """å˜ä¸€ã®ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
        start_time = time.time()
        
        request_data = {
            "prompt": prompt,
            "model_name": model_name,
            "max_tokens": 50,
            "temperature": 0.8
        }
        
        try:
            await self.init_session()
            async with self.session.post(f"{self.base_url}/generate", json=request_data) as response:
                end_time = time.time()
                response_time = end_time - start_time
                
                if response.status == 200:
                    result = await response.json()
                    response_text = result['response']
                    return {
                        "request_id": request_id,
                        "success": True,
                        "response_time": response_time,
                        "response_length": len(response_text),
                        "response": response_text[:100] + "..." if len(response_text) > 100 else response_text
                    }
                else:
                    error_text = await response.text()
                    return {
                        "request_id": request_id,
                        "success": False,
                        "response_time": response_time,
                        "error": f"HTTP {response.status}: {error_text}"
                    }
                    
        except Exception as e:
            end_time = time.time()
            response_time = end_time - start_time
            return {
                "request_id": request_id,
                "success": False,
                "response_time": response_time,
                "error": str(e)
            }
    
    async def test_concurrent_requests(self, num_requests: int = 5, model_name: str = None):
        """ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸš€ ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ ({num_requests}å€‹)")
        
        if not model_name:
            models = await self.test_models()
            if not models:
                print("âŒ ãƒ†ã‚¹ãƒˆç”¨ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            model_name = models[0]['name']
        
        print(f"ğŸ“„ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model_name}")
        
        # ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æº–å‚™
        prompts = [
            "Once upon a time in a magical forest,",
            "The future of artificial intelligence is",
            "In a world where technology has advanced,",
            "The secrets of the universe can be found",
            "A young adventurer discovered a hidden",
            "The power of friendship can overcome",
            "In the depths of the ocean lives",
            "The ancient prophecy foretells that",
            "Science has revealed many mysteries, but",
            "The journey of a thousand miles begins"
        ]
        
        start_time = time.time()
        
        # ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
        tasks = []
        for i in range(num_requests):
            prompt = prompts[i % len(prompts)]
            task = self.single_generate_request(prompt, model_name, i + 1)
            tasks.append(task)
        
        print("â³ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        results = await asyncio.gather(*tasks)
        
        total_time = time.time() - start_time
        
        # çµæœåˆ†æ
        successful = [r for r in results if r['success']]
        failed = [r for r in results if not r['success']]
        
        print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   âœ… æˆåŠŸ: {len(successful)}/{num_requests}")
        print(f"   âŒ å¤±æ•—: {len(failed)}/{num_requests}")
        print(f"   â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        
        if successful:
            avg_response_time = sum(r['response_time'] for r in successful) / len(successful)
            min_response_time = min(r['response_time'] for r in successful)
            max_response_time = max(r['response_time'] for r in successful)
            
            print(f"   ğŸ“ˆ å¹³å‡å¿œç­”æ™‚é–“: {avg_response_time:.2f}ç§’")
            print(f"   âš¡ æœ€é€Ÿå¿œç­”: {min_response_time:.2f}ç§’")
            print(f"   ğŸŒ æœ€é…å¿œç­”: {max_response_time:.2f}ç§’")
            
            print(f"\nğŸ“ ç”Ÿæˆçµæœä¾‹:")
            for i, result in enumerate(successful[:3]):
                print(f"   {i+1}. [{result['response_time']:.2f}s] {result['response']}")
        
        if failed:
            print(f"\nâŒ å¤±æ•—è©³ç´°:")
            for result in failed:
                print(f"   Request {result['request_id']}: {result['error']}")
        
        return results
    
    async def test_sequential_requests(self, num_requests: int = 5, model_name: str = None):
        """é€æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆï¼ˆæ¯”è¼ƒç”¨ï¼‰"""
        print(f"\nğŸ”„ é€æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ ({num_requests}å€‹)")
        
        if not model_name:
            models = await self.test_models()
            if not models:
                print("âŒ ãƒ†ã‚¹ãƒˆç”¨ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            model_name = models[0]['name']
        
        prompts = [
            "Tell me a short story about",
            "Explain the concept of",
            "What would happen if",
            "Describe the importance of",
            "How does technology impact"
        ]
        
        start_time = time.time()
        results = []
        
        for i in range(num_requests):
            prompt = prompts[i % len(prompts)]
            print(f"   ğŸ“¤ Request {i+1}/{num_requests}...")
            result = await self.single_generate_request(prompt, model_name, i + 1)
            results.append(result)
        
        total_time = time.time() - start_time
        
        successful = [r for r in results if r['success']]
        print(f"\nğŸ“Š é€æ¬¡ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   âœ… æˆåŠŸ: {len(successful)}/{num_requests}")
        print(f"   â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        
        if successful:
            avg_response_time = sum(r['response_time'] for r in successful) / len(successful)
            print(f"   ğŸ“ˆ å¹³å‡å¿œç­”æ™‚é–“: {avg_response_time:.2f}ç§’")
        
        return results

async def main():
    if len(sys.argv) > 1:
        base_url = sys.argv[1]
    else:
        base_url = "http://localhost:9000"
    
    num_concurrent = int(sys.argv[2]) if len(sys.argv) > 2 else 5
    
    print("="*60)
    print("ğŸ§ª ComeAPI ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("="*60)
    print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {base_url}")
    print(f"âš¡ ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {num_concurrent}")
    print("="*60)
    
    tester = LoadBalancerTester(base_url)
    
    try:
        # 1. çŠ¶æ…‹ç¢ºèª
        status = await tester.test_status()
        if not status:
            print("âŒ ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
            return
        
        # 2. ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ç¢ºèª
        models = await tester.test_models()
        if not models:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        model_name = models[0]['name']
        
        # 3. é€æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ
        await tester.test_sequential_requests(3, model_name)
        
        # 4. ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ
        await tester.test_concurrent_requests(num_concurrent, model_name)
        
        print("\nâœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†!")
        
    finally:
        await tester.close_session()

if __name__ == "__main__":
    asyncio.run(main()) 