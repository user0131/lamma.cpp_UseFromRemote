# ComeAPI - ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼å‹ä¸¦åˆ—å‡¦ç†LLMã‚µãƒ¼ãƒãƒ¼

llama-cpp-pythonã‚’åˆ©ç”¨ã—ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ä¸¦åˆ—å‡¦ç†APIã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚ãƒªãƒ¢ãƒ¼ãƒˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰æœ€å¤§30ã®åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã¾ã™ã€‚

## ä¸»ãªæ©Ÿèƒ½

- **ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼**: æœ€å¤§30ã®åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ï¼ˆ8070-8099ãƒãƒ¼ãƒˆï¼‰
- **è‡ªå‹•è² è·åˆ†æ•£**: ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³æ–¹å¼ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’åˆ†æ•£
- **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã®è‡ªå‹•ç›£è¦–ãƒ»å¾©æ—§ï¼ˆ30ç§’é–“éš”ï¼‰
- **FastAPIãƒ™ãƒ¼ã‚¹**: æ¨™æº–çš„ãªREST API
- **ãƒªãƒ¢ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµŒç”±ã§ã®å®‰å…¨ãªåˆ©ç”¨
- **Metal GPUåŠ é€Ÿ**: Macç’°å¢ƒã§ã®é«˜é€Ÿæ¨è«–
- **ã‚·ãƒ³ãƒ—ãƒ«æ§‹æˆ**: å¿…è¦æœ€å°é™ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«**: 5å°ã€œ30å°ã¾ã§æŸ”è»Ÿãªè¨­å®š

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

```
Remote Client PC â”€â”€â”€ Network â”€â”€â”€ Load Balancer (port 9000) â”€â”€â”€ Backend 1 (port 8070)
                                                             â”œâ”€â”€ Backend 2 (port 8071)
                                                             â”œâ”€â”€ Backend 3 (port 8072)
                                                             â”œâ”€â”€ ...
                                                             â””â”€â”€ Backend 30 (port 8099)
```

## ğŸ“‹ å‰ææ¡ä»¶

- Python 3.8ä»¥ä¸Š
- Poetryï¼ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†ï¼‰
- macOSæ¨å¥¨ï¼ˆMetal GPUåŠ é€Ÿå¯¾å¿œï¼‰
- **32GBä»¥ä¸Šã®RAM**ï¼ˆ10å°æ§‹æˆæ™‚ï¼‰**512GBæ¨å¥¨**ï¼ˆ30å°æ§‹æˆæ™‚ãƒ»Mac Studioï¼‰
- **ç©ºããƒãƒ¼ãƒˆ**: 8070-8099, 9000
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: ãƒªãƒ¢ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/user0131/lamma.cpp_UseFromRemote.git
cd lamma.cpp_UseFromRemote

# ä»®æƒ³ç’°å¢ƒã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã«ä½œæˆ
poetry config virtualenvs.in-project true

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
poetry install --with llama-cpp-python

# Metalå¯¾å¿œllama-cpp-pythonã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆMacï¼‰
poetry run pip install --force-reinstall --no-cache-dir "cmake>=3.21.0"
CMAKE_ARGS="-DLLAMA_METAL=on" poetry run pip install --force-reinstall --no-cache-dir llama-cpp-python

# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è¿½åŠ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
source .venv/bin/activate
pip install aiohttp requests
pip install "uvicorn[standard]" fastapi

```

### 2. ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```bash
# ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
mkdir -p models

# Qwen3-4Bãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰
curl -L https://huggingface.co/Qwen/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-Q4_K_M.gguf -o models/qwen3-4b.Q4_K_M.gguf
```

## ğŸ’» ã‚µãƒ¼ãƒãƒ¼èµ·å‹•

### ğŸš€ ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•æ‰‹é †

#### Step 1: ä»®æƒ³ç’°å¢ƒã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–
```bash
# å¿…é ˆï¼šä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–
source .venv/bin/activate
```

#### Step 2: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
```bash
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ç¾¤èµ·å‹•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5å°: 8070-8074ï¼‰
python src/start_backends.py models

# 10å°ã§èµ·å‹•ï¼ˆ8070-8079ï¼‰æ¨å¥¨ï¼š32GBç’°å¢ƒ
python src/start_backends.py models 0.0.0.0 8070 10

# æœ€å¤§30å°ã§èµ·å‹•ï¼ˆ8070-8099ï¼‰æ¨å¥¨ï¼šMac Studio 512GBç’°å¢ƒ
python src/start_backends.py models 0.0.0.0 8070 30
```

#### Step 3: ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼èµ·å‹•ï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
```bash
# æ–°ã—ã„ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–
source .venv/bin/activate

# ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼èµ·å‹•ï¼ˆãƒªãƒ¢ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹å¯¾å¿œï¼‰
python src/load_balancer.py 0.0.0.0 8070 10 0.0.0.0 9000

# 30å°å¯¾å¿œï¼ˆMac Studio 512GBç’°å¢ƒï¼‰
python src/load_balancer.py 0.0.0.0 8070 30 0.0.0.0 9000
```

#### Step 4: å‹•ä½œç¢ºèª
```bash
# ãƒ­ãƒ¼ã‚«ãƒ«å‹•ä½œç¢ºèª
curl http://localhost:9000/

# ãƒªãƒ¢ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹ç¢ºèªï¼ˆã‚µãƒ¼ãƒãƒ¼IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŒ‡å®šï¼‰
curl http://[ã‚µãƒ¼ãƒãƒ¼IPã‚¢ãƒ‰ãƒ¬ã‚¹]:9000/
```

### âš ï¸ é‡è¦ãªæ³¨æ„ç‚¹
1. **ä»®æƒ³ç’°å¢ƒ**: å¿…ãš `source .venv/bin/activate` ã‚’å®Ÿè¡Œ
2. **å®Ÿè¡Œå ´æ‰€**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œ
3. **ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹**: `models` ã§ãƒ«ãƒ¼ãƒˆã®modelsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
4. **ä¾å­˜é–¢ä¿‚**: aiohttp, requestsãŒå¿…è¦ï¼ˆpip installï¼‰
5. **èµ·å‹•é †åº**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ â†’ ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®é †åºå¿…é ˆ
6. **ãƒãƒ¼ãƒˆç¢ºèª**: 8070-8099, 9000ãŒç©ºã„ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
7. **ã‚¿ãƒ¼ãƒŸãƒŠãƒ«**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã¯åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§èµ·å‹•
8. **é•·æœŸé–“å®Ÿè¡Œ**: ãƒ­ã‚°å‡ºåŠ›ç„¡åŠ¹åŒ–æ¸ˆã¿ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡å¢—åŠ ãªã—ï¼‰
9. **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ•° Ã— 2.3GBï¼ˆQwen3-4Bä½¿ç”¨æ™‚ï¼‰
10. **Mac Studio**: 512GBãƒ¡ãƒ¢ãƒªç’°å¢ƒã§30å°ä¸¦åˆ—å‡¦ç†ã«æœ€é©åŒ–
11. **ãƒªãƒ¢ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã§ `0.0.0.0` ã‚’æŒ‡å®š

## ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®š

### ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š

#### macOS
```bash
# ãƒãƒ¼ãƒˆé–‹æ”¾ï¼ˆ8070-8099, 9000ï¼‰
sudo pfctl -f /etc/pf.conf
sudo pfctl -e

# ä¸€æ™‚çš„ãªãƒãƒ¼ãƒˆé–‹æ”¾
sudo pfctl -d  # ç„¡åŠ¹åŒ–ï¼ˆé–‹ç™ºæ™‚ã®ã¿ï¼‰
```

#### æ‰‹å‹•ã§ã®ãƒãƒ¼ãƒˆç¢ºèª
```bash
# ãƒãƒ¼ãƒˆä½¿ç”¨çŠ¶æ³ç¢ºèª
lsof -i :8070-8099
lsof -i :9000

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šç¢ºèª
netstat -an | grep LISTEN | grep -E ":(8070|8071|8072|8073|8074|9000)"
```

### ã‚µãƒ¼ãƒãƒ¼IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®ç¢ºèª
```bash
# ãƒ­ãƒ¼ã‚«ãƒ«IPã‚¢ãƒ‰ãƒ¬ã‚¹ç¢ºèª
ifconfig | grep "inet " | grep -v 127.0.0.1

# ã¾ãŸã¯
ipconfig getifaddr en0  # Wi-Fi
ipconfig getifaddr en1  # æœ‰ç·šLAN
```

## ğŸŒ ãƒªãƒ¢ãƒ¼ãƒˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã®åˆ©ç”¨

### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```bash
# ã‚µãƒ¼ãƒãƒ¼IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’192.168.1.100ã¨ä»®å®š

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
curl http://192.168.1.100:9000/status

# ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
curl http://192.168.1.100:9000/models

# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
curl -X POST http://192.168.1.100:9000/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "qwen3-4b.Q4_K_M.gguf",
    "prompt": "ãƒªãƒ¢ãƒ¼ãƒˆã‹ã‚‰æ¥ç¶šãƒ†ã‚¹ãƒˆ",
    "max_tokens": 50
  }'
```

### Pythonã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¾‹

```python
import requests

# ã‚µãƒ¼ãƒãƒ¼IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’è¨­å®š
SERVER_IP = "192.168.1.100"  # å®Ÿéš›ã®ã‚µãƒ¼ãƒãƒ¼IPã«å¤‰æ›´
API_URL = f"http://{SERVER_IP}:9000"

# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
response = requests.post(f'{API_URL}/generate', json={
    "prompt": "Pythonã§ãƒªãƒ¢ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ",
    "model_name": "qwen3-4b.Q4_K_M.gguf",
    "max_tokens": 200,
    "temperature": 0.8
})

result = response.json()
print(result['response'])

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
status = requests.get(f'{API_URL}/status').json()
print(f"ç¨¼åƒä¸­ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: {status['healthy_backends']}/{status['total_backends']}")
```

### JavaScript/Node.js ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¾‹

```javascript
const axios = require('axios');

const SERVER_IP = "192.168.1.100";  // å®Ÿéš›ã®ã‚µãƒ¼ãƒãƒ¼IPã«å¤‰æ›´
const API_URL = `http://${SERVER_IP}:9000`;

async function generateText() {
    try {
        const response = await axios.post(`${API_URL}/generate`, {
            prompt: "JavaScriptã‹ã‚‰ã®ãƒªãƒ¢ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ",
            model_name: "qwen3-4b.Q4_K_M.gguf",
            max_tokens: 200,
            temperature: 0.8
        });
        
        console.log(response.data.response);
    } catch (error) {
        console.error('ã‚¨ãƒ©ãƒ¼:', error.message);
    }
}

generateText();
```

## ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚¬ã‚¤ãƒ‰

| ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ•° | æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | æ¨å¥¨ã‚·ã‚¹ãƒ†ãƒ  | ç”¨é€” |
|-------------|---------------|-------------|-----|
| 5å° | ç´„11.5GB | 16GB+ | é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç’°å¢ƒ |
| 10å° | ç´„23GB | 32GB+ | 32GBãƒ¡ãƒ¢ãƒªç’°å¢ƒã®æœ€é©æ§‹æˆ |
| 15å° | ç´„34.5GB | 64GB+ | é«˜æ€§èƒ½ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ |
| 20å° | ç´„46GB | 64GB+ | å¤§è¦æ¨¡æœ¬ç•ªç’°å¢ƒ |
| **30å°** | **ç´„69GB** | **512GB+** | **Mac Studioæ¨å¥¨æ§‹æˆ** |

### ğŸ–¥ï¸ **ç’°å¢ƒåˆ¥æ¨å¥¨æ§‹æˆ**

| ç’°å¢ƒ | ãƒ¡ãƒ¢ãƒª | æ¨å¥¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ•° | æœŸå¾…æ€§èƒ½ |
|-----|------|---------------|---------|
| é–‹ç™ºç’°å¢ƒ | 16GB | 5å° | åŸºæœ¬åˆ©ç”¨ |
| **æ±ç”¨ç’°å¢ƒ** | **32GB** | **10å°** | **ãƒãƒ©ãƒ³ã‚¹é‡è¦–** |
| ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ | 64GB | 15-20å° | é«˜æ€§èƒ½ |
| **Mac Studio** | **512GB** | **30å°** | **æœ€å¤§æ€§èƒ½** |

## ğŸ“Š APIä»•æ§˜

### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

| ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ | ãƒ¡ã‚½ãƒƒãƒ‰ | èª¬æ˜ |
|---------------|---------|------|
| `/` | GET | ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼çŠ¶æ…‹ |
| `/status` | GET | è©³ç´°ãªã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ |
| `/models` | GET | åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ |
| `/generate` | POST | ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ |

### ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ/generateï¼‰

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å‹ | å¿…é ˆ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|---|------|-----------|------|
| `prompt` | string | âœ“ | - | å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ |
| `model_name` | string | âœ“ | - | ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å |
| `max_tokens` | integer | - | 100 | æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•° |
| `temperature` | float | - | 0.8 | ç”Ÿæˆæ¸©åº¦ |
| `top_k` | integer | - | 40 | Top-k ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° |
| `top_p` | float | - | 0.9 | Top-p ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° |

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼
**ç—‡çŠ¶**: `ModuleNotFoundError: No module named 'aiohttp'`

**è§£æ±ºç­–**:
```bash
source .venv/bin/activate
pip install aiohttp requests
```

### 2. ãƒªãƒ¢ãƒ¼ãƒˆæ¥ç¶šã‚¨ãƒ©ãƒ¼
**ç—‡çŠ¶**: `Connection refused` ã¾ãŸã¯æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

**è§£æ±ºç­–**:
```bash
# 1. ã‚µãƒ¼ãƒãƒ¼å´ã§ãƒã‚¤ãƒ³ãƒ‰ã‚¢ãƒ‰ãƒ¬ã‚¹ç¢ºèª
python src/start_backends.py models 0.0.0.0 8070 5  # 0.0.0.0ã‚’æŒ‡å®š
python src/load_balancer.py 0.0.0.0 8070 5 0.0.0.0 9000

# 2. ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ç¢ºèª
sudo pfctl -d  # ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ï¼ˆé–‹ç™ºæ™‚ã®ã¿ï¼‰

# 3. ãƒãƒ¼ãƒˆç¢ºèª
lsof -i :9000
```

### 3. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ¥ç¶šã‚¨ãƒ©ãƒ¼
**ç—‡çŠ¶**: `503 Service Unavailable` ã¾ãŸã¯ `502 Bad Gateway`

**è§£æ±ºç­–**:
```bash
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çŠ¶æ…‹ç¢ºèª
curl http://[ã‚µãƒ¼ãƒãƒ¼IP]:8070/
curl http://[ã‚µãƒ¼ãƒãƒ¼IP]:8071/
curl http://[ã‚µãƒ¼ãƒãƒ¼IP]:9000/status
```

### 4. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼
**ç—‡çŠ¶**: `OutOfMemoryError` ã¾ãŸã¯ç•°å¸¸ã«é…ã„å¿œç­”

**è§£æ±ºç­–**:
```bash
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
ps aux | grep "python.*server.py" | awk '{sum += $6} END {print "Total Memory: " sum/1024 " MB"}'

# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ•°ã‚’å‰Šæ¸›
python src/start_backends.py models 0.0.0.0 8070 5
```

## ğŸ“‚ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ï¼ˆå¿…è¦æœ€å°é™ï¼‰

```
.
â”œâ”€â”€ README.md                   # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”œâ”€â”€ pyproject.toml              # Poetryè¨­å®š
â”œâ”€â”€ poetry.lock                 # ä¾å­˜é–¢ä¿‚ãƒ­ãƒƒã‚¯
â”œâ”€â”€ .gitignore                  # é™¤å¤–è¨­å®š
â”œâ”€â”€ models/                     # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â””â”€â”€ qwen3-4b.Q4_K_M.gguf   # Qwen3-4Bãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ .venv/                      # ä»®æƒ³ç’°å¢ƒ
â”œâ”€â”€ .git/                       # Gitç®¡ç†
â”œâ”€â”€ src/                        # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ backend_server.py       # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼
â”‚   â”œâ”€â”€ start_backends.py       # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç¾¤èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â””â”€â”€ load_balancer.py        # ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼æœ¬ä½“
â””â”€â”€ test/                       # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
    â””â”€â”€ test_load_balancer.py   # ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### åŸºæœ¬æ§‹æˆï¼ˆ5å°ï¼‰
```bash
# 1. ä»®æƒ³ç’°å¢ƒã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–
source .venv/bin/activate

# 2. ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
python src/start_backends.py models 0.0.0.0 8070 5

# 3. æ–°ã—ã„ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼èµ·å‹•
source .venv/bin/activate
python src/load_balancer.py 0.0.0.0 8070 5 0.0.0.0 9000

# 4. ãƒªãƒ¢ãƒ¼ãƒˆã‹ã‚‰å‹•ä½œç¢ºèª
curl http://[ã‚µãƒ¼ãƒãƒ¼IP]:9000/status
```

### Mac Studioï¼ˆ30å°ï¼‰æ§‹æˆ
```bash
# 1. Mac Studio 512GBãƒ¡ãƒ¢ãƒªç¢ºèª
system_profiler SPHardwareDataType | grep Memory

# 2. 30å°ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰èµ·å‹•
python src/start_backends.py models 0.0.0.0 8070 30

# 3. å¯¾å¿œãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼èµ·å‹•
python src/load_balancer.py 0.0.0.0 8070 30 0.0.0.0 9000
```

### 32GBç’°å¢ƒï¼ˆ10å°ï¼‰æ§‹æˆ
```bash
# 1. 32GBãƒ¡ãƒ¢ãƒªç’°å¢ƒã§ã®æ¨å¥¨æ§‹æˆ
python src/start_backends.py models 0.0.0.0 8070 10

# 2. å¯¾å¿œãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼èµ·å‹•
python src/load_balancer.py 0.0.0.0 8070 10 0.0.0.0 9000
```